import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import spectral.io.envi as envi
from pathlib import Path
import numpy as np
from sklearn.metrics import confusion_matrix
import torch.nn.functional as F
import json
import random

device = "cuda" if torch.cuda.is_available() else "cpu"

class SpectralPatchDataset(Dataset):
    def __init__(self, root_dir, patch_size=5, stride=5, class_mapping_file=None, file_list=None, mode='train'):
        self.root_dir = Path(root_dir)
        self.patch_size = patch_size
        self.stride = stride
        self.mode = mode
        self.samples = []
        self.labels = []
        self.class_map = {}
        self.class_names = []

        self.class_mapping = {}
        if class_mapping_file is not None:
            with open(class_mapping_file, 'r') as f:
                self.class_mapping = json.load(f)

        if file_list is not None:
            hdr_files = [f for f in sorted(self.root_dir.rglob("*.hdr")) if f.name in file_list]
        else:
            hdr_files = sorted(self.root_dir.rglob("*.hdr"))

        original_class_names = sorted(list({f.stem.split("_")[0] for f in hdr_files}))

        self.original_to_mapped = {}
        if self.class_mapping:
            for old_class in original_class_names:
                for new_class, old_classes in self.class_mapping.items():
                    if old_class in old_classes:
                        self.original_to_mapped[old_class] = new_class
                        break
        else:
            for old_class in original_class_names:
                self.original_to_mapped[old_class] = old_class

        self.mapped_class_names = sorted(list(set(self.original_to_mapped.values())))
        for idx, name in enumerate(self.mapped_class_names):
            self.class_map[name] = idx
            self.class_names.append(name)

        for hdr_file in hdr_files:
            prefix = hdr_file.stem.split("_")[0]
            if prefix not in self.original_to_mapped:
                continue
            mapped_class = self.original_to_mapped[prefix]
            class_id = self.class_map[mapped_class]
            img = envi.open(str(hdr_file))
            cube = np.array(img.load(), dtype=np.float32)
            cube_tensor = torch.from_numpy(cube).float().unsqueeze(0)
            patches = F.unfold(cube_tensor, kernel_size=(patch_size, patch_size), stride=stride, padding=1)
            patches = patches.squeeze(0).reshape(cube.shape[0], patch_size*patch_size, patches.shape[-1]).permute(2,0,1)
            for patch in patches:
                self.samples.append(patch)
                self.labels.append(class_id)

        self.num_classes = len(self.class_names)

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        x = self.samples[idx].reshape(-1)
        y = self.labels[idx]
        return torch.FloatTensor(x), torch.LongTensor([y])[0]

def split_files_by_class(hdr_files, class_mapping, train_ratio=0.7, random_seed=42):
    random.seed(random_seed)
    files_by_original_class = {}
    for f in hdr_files:
        prefix = f.stem.split("_")[0]
        files_by_original_class.setdefault(prefix, []).append(f)
    original_to_mapped = {old_class: new_class for new_class, old_list in class_mapping.items() for old_class in old_list}
    train_files, test_files = [], []
    for old_class, files in files_by_original_class.items():
        if old_class in original_to_mapped:
            mapped_class = original_to_mapped[old_class]
            random.shuffle(files)
            if len(files) == 1:
                train_files.append(files[0])
                test_files.append(files[0])
            elif len(files) == 2:
                train_files.append(files[0])
                test_files.append(files[1])
            else:
                n_train = int(train_ratio * len(files))
                train_files.extend(files[:n_train])
                test_files.extend(files[n_train:])
    return train_files, test_files

class BasicBlock3D(nn.Module):
    expansion = 1
    def __init__(self, in_planes, planes, stride=1):
        super().__init__()
        self.conv1 = nn.Conv3d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm3d(planes)
        self.relu = nn.ReLU(inplace=True)
        self.conv2 = nn.Conv3d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm3d(planes)
        self.downsample = None
        if stride != 1 or in_planes != planes:
            self.downsample = nn.Sequential(
                nn.Conv3d(in_planes, planes, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm3d(planes)
            )
    def forward(self, x):
        identity = x
        out = self.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        if self.downsample:
            identity = self.downsample(identity)
        out += identity
        return self.relu(out)

class ResNet3D(nn.Module):
    def __init__(self, block, layers, num_classes):
        super().__init__()
        self.in_planes = 8
        self.conv1 = nn.Conv3d(1, 8, kernel_size=(7,3,3), stride=(2,1,1), padding=(3,1,1), bias=False)
        self.bn1 = nn.BatchNorm3d(8)
        self.relu = nn.ReLU(inplace=True)
        self.layer1 = self._make_layer(block, 16, layers[0], stride=1)
        self.layer2 = self._make_layer(block, 32, layers[1], stride=2)
        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)
        self.avgpool = nn.AdaptiveAvgPool3d((1,1,1))
        self.fc = nn.Linear(64*block.expansion, num_classes)
    def _make_layer(self, block, planes, blocks, stride):
        layers = [block(self.in_planes, planes, stride)]
        self.in_planes = planes * block.expansion
        for _ in range(1, blocks):
            layers.append(block(self.in_planes, planes))
        return nn.Sequential(*layers)
    def forward(self, x):
        x = x.view(x.size(0), 1, 272, 5, 5)
        x = self.relu(self.bn1(self.conv1(x)))
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        return self.fc(x)

def ResNet3D18(num_classes):
    return ResNet3D(BasicBlock3D, [2,2,2], num_classes)

def cal_results(matrix):
    number=0; summ=0
    AA=np.zeros(matrix.shape[0])
    for i in range(matrix.shape[0]):
        number+=matrix[i,i]
        AA[i]=matrix[i,i]/np.sum(matrix[i,:]) if np.sum(matrix[i,:])!=0 else 0
        summ+=np.sum(matrix[i,:])*np.sum(matrix[:,i])
    OA=number/np.sum(matrix); AA_mean=np.mean(AA)
    pe=summ/(np.sum(matrix)**2)
    Kappa=(OA-pe)/(1-pe)
    return OA,AA_mean,Kappa,AA

data_dir="extrudes_eroded"
class_mapping_file="mapping.json"
patch_size=5; stride=5
batch_size=64; epochs=50; learning_rate=5e-4; train_ratio=0.7

all_hdr_files=sorted(Path(data_dir).rglob("*.hdr"))
try:
    with open(class_mapping_file,'r') as f: class_mapping=json.load(f)
    train_files,test_files=split_files_by_class(all_hdr_files,class_mapping,train_ratio)
except FileNotFoundError:
    random.seed(42)
    random.shuffle(all_hdr_files)
    n_train=int(train_ratio*len(all_hdr_files))
    train_files=all_hdr_files[:n_train]; test_files=all_hdr_files[n_train:]
    class_mapping=None

train_dataset=SpectralPatchDataset(root_dir=data_dir,patch_size=patch_size,stride=stride,
                                   class_mapping_file=class_mapping_file if class_mapping else None,
                                   file_list=[f.name for f in train_files],mode='train')
test_dataset=SpectralPatchDataset(root_dir=data_dir,patch_size=patch_size,stride=stride,
                                  class_mapping_file=class_mapping_file if class_mapping else None,
                                  file_list=[f.name for f in test_files],mode='test')

train_loader=DataLoader(train_dataset,batch_size=batch_size,shuffle=True)
test_loader=DataLoader(test_dataset,batch_size=batch_size,shuffle=False)

model=ResNet3D18(num_classes=train_dataset.num_classes).to(device)
criterion=nn.CrossEntropyLoss()
optimizer=optim.Adam(model.parameters(),lr=learning_rate)

for epoch in range(epochs):
    model.train()
    total_loss=0; correct=0; total=0
    for x,y in train_loader:
        x,y=x.to(device),y.to(device)
        optimizer.zero_grad()
        out=model(x)
        loss=criterion(out,y)
        loss.backward()
        optimizer.step()
        total_loss+=loss.item()
        _,predicted=torch.max(out,1)
        total+=y.size(0); correct+=(predicted==y).sum().item()
    train_acc=100*correct/total

    if (epoch+1)%5==0 or epoch==epochs-1:
        model.eval()
        all_preds=[]; all_labels=[]
        with torch.no_grad():
            for x,y in test_loader:
                x=x.to(device)
                out=model(x)
                _,pred=torch.max(out,1)
                all_preds.extend(pred.cpu().numpy())
                all_labels.extend(y.numpy())
        matrix=confusion_matrix(all_labels,all_preds)
        OA,AA_mean,Kappa,AA=cal_results(matrix)
        print(f"Epoch {epoch+1} | OA={OA:.4f} AA={AA_mean:.4f} Kappa={Kappa:.4f}")