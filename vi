import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split, Subset
import spectral.io.envi as envi
from pathlib import Path
import numpy as np
from einops import rearrange, repeat
from sklearn.metrics import confusion_matrix
import json
import random

device = "cuda" if torch.cuda.is_available() else "cpu"

class SpectralPatchDataset(Dataset):
    def __init__(self, root_dir, patch_size=5, stride=5, class_mapping_file=None, 
                 file_list=None, mode='train', mask_type='checkerboard'):
        self.root_dir = Path(root_dir)
        self.patch_size = patch_size
        self.stride = stride
        self.mode = mode
        self.mask_type = mask_type
        self.samples = []
        self.labels = []
        self.class_map = {}
        self.class_names = []
        self.file_patches = {}
        self.single_file_classes = {}
        
        # Charger le mapping des classes si fourni
        self.class_mapping = {}
        if class_mapping_file is not None:
            with open(class_mapping_file, 'r') as f:
                self.class_mapping = json.load(f)
            print(f"Mapping des classes charg√©: {self.class_mapping}")
        
        # Obtenir la liste des fichiers
        if file_list is not None:
            hdr_files = [f for f in sorted(self.root_dir.rglob("*.hdr")) if f.name in file_list]
        else:
            hdr_files = sorted(self.root_dir.rglob("*.hdr"))
        
        # Premier passage pour cr√©er le mapping des classes originales
        original_class_names = set()
        for hdr_file in hdr_files:
            name = hdr_file.stem
            prefix = name.split("_")[0]
            original_class_names.add(prefix)
        
        original_class_names = sorted(list(original_class_names))
        
        # Cr√©er le mapping des classes originales vers les nouvelles classes
        self.original_to_mapped = {}
        self.mapped_class_names = []
        
        if self.class_mapping:
            for old_class in original_class_names:
                found = False
                for new_class, old_classes in self.class_mapping.items():
                    if old_class in old_classes:
                        self.original_to_mapped[old_class] = new_class
                        if new_class not in self.mapped_class_names:
                            self.mapped_class_names.append(new_class)
                        found = True
                        break
                if not found:
                    print(f"Attention: La classe {old_class} n'est pas mapp√©e, elle sera ignor√©e")
        else:
            for old_class in original_class_names:
                self.original_to_mapped[old_class] = old_class
            self.mapped_class_names = original_class_names.copy()
        
        self.mapped_class_names = sorted(self.mapped_class_names)
        for idx, name in enumerate(self.mapped_class_names):
            self.class_map[name] = idx
            self.class_names.append(name)
        
        self.num_classes = len(self.class_names)
        
        # Compter le nombre de fichiers par classe mapp√©e
        class_file_count = {}
        for hdr_file in hdr_files:
            name = hdr_file.stem
            prefix = name.split("_")[0]
            if prefix in self.original_to_mapped:
                mapped_class = self.original_to_mapped[prefix]
                class_file_count[mapped_class] = class_file_count.get(mapped_class, 0) + 1
        
        # Identifier les classes avec un seul fichier
        self.single_file_classes = {cls for cls, count in class_file_count.items() if count == 1}
        print(f"Classes avec un seul fichier: {self.single_file_classes}")
        
        # Charger les donn√©es
        all_samples = []
        all_labels = []
        
        for hdr_file in hdr_files:
            name = hdr_file.stem
            prefix = name.split("_")[0]
            
            if prefix not in self.original_to_mapped:
                continue
            
            mapped_class = self.original_to_mapped[prefix]
            class_id = self.class_map[mapped_class]
            
            img = envi.open(str(hdr_file))
            cube = np.array(img.load(), dtype=np.float32)
            B, H, W = cube.shape
            
            # Mirror padding
            padded_cube = self._mirror_hsi(cube, patch_size)
            cube_tensor = torch.from_numpy(padded_cube).float()
            
            # V√©rifier si c'est une classe avec un seul fichier
            if mapped_class in self.single_file_classes:
                # Cr√©er un masque pour ce fichier
                mask = self._create_spatial_mask(H, W)
                
                # Sauvegarder le masque
                self.file_patches[hdr_file.name] = {
                    'mask': mask,
                    'class': mapped_class,
                    'class_id': class_id
                }
                
                # Extraire les patches selon le mode
                patches = self._extract_patches_with_mask(cube_tensor, patch_size, stride, mask)
            else:
                # Extraction normale sans masque
                patches = self._extract_patches(cube_tensor, patch_size, stride)
            
            for patch in patches:
                all_samples.append(patch)
                all_labels.append(class_id)
        
        self.samples = all_samples
        self.labels = all_labels
        
        print(f"Mode {mode}: {len(self.samples)} patches charg√©s")
    
    def _mirror_hsi(self, cube, patch):
        B, H, W = cube.shape
        padding = patch // 2
        mirror_hsi = np.zeros((B, H + 2*padding, W + 2*padding), dtype=float)
        mirror_hsi[:, padding:padding+H, padding:padding+W] = cube
        for i in range(padding):
            mirror_hsi[:, padding:padding+H, i] = cube[:, :, padding-i-1]
        for i in range(padding):
            mirror_hsi[:, padding:padding+H, W+padding+i] = cube[:, :, W-1-i]
        for i in range(padding):
            mirror_hsi[:, i, :] = mirror_hsi[:, padding*2-i-1, :]
        for i in range(padding):
            mirror_hsi[:, H+padding+i, :] = mirror_hsi[:, H+padding-1-i, :]
        return mirror_hsi
    
    def _create_spatial_mask(self, height, width, cell_size=4):
        """Cr√©e un masque en damier pour les fichiers uniques"""
        mask = np.zeros((height, width), dtype=bool)
        for i in range(height):
            for j in range(width):
                if ((i // cell_size) + (j // cell_size)) % 2 == 0:
                    mask[i, j] = True  # Train
                else:
                    mask[i, j] = False  # Test
        return mask
    
    def _extract_patches(self, cube_tensor, patch_size, stride):
        B, H, W = cube_tensor.shape
        cube_tensor = cube_tensor.unsqueeze(0)
        patches = torch.nn.functional.unfold(cube_tensor, kernel_size=(patch_size, patch_size), 
                                            dilation=1, stride=stride)
        L = patches.shape[-1]
        patches = patches.squeeze(0).reshape(B, patch_size * patch_size, L).permute(2, 0, 1)
        patches = patches.reshape(L, B, patch_size, patch_size)
        
        patch_list = []
        for i in range(L):
            patch = patches[i].numpy()
            patch_list.append(patch)
        return patch_list
    
    def _extract_patches_with_mask(self, cube_tensor, patch_size, stride, mask):
        B, H, W = cube_tensor.shape
        padding = patch_size // 2
        patch_list = []
        
        for i in range(0, H - patch_size + 1, stride):
            for j in range(0, W - patch_size + 1, stride):
                center_i = i + patch_size//2 - padding
                center_j = j + patch_size//2 - padding
                
                if 0 <= center_i < mask.shape[0] and 0 <= center_j < mask.shape[1]:
                    if self.mode == 'train' and mask[center_i, center_j]:
                        patch = cube_tensor[:, i:i+patch_size, j:j+patch_size]
                        patch_np = patch.numpy()
                        patch_list.append(patch_np)
                    elif self.mode == 'test' and not mask[center_i, center_j]:
                        patch = cube_tensor[:, i:i+patch_size, j:j+patch_size]
                        patch_np = patch.numpy()
                        patch_list.append(patch_np)
        
        return patch_list
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        x = self.samples[idx]  # Shape: [num_bands, patch_size, patch_size]
        y = self.labels[idx]
        
        # Aplatir le patch en un vecteur pour ViT
        x = x.reshape(x.shape[0], -1).permute(1, 0)  # [patch_size*patch_size, num_bands]
        x = x.reshape(-1)  # [patch_size*patch_size*num_bands]
        
        return torch.FloatTensor(x), torch.LongTensor([y])[0]

def split_files_by_class(hdr_files, class_mapping, train_ratio=0.7, random_seed=42):
    random.seed(random_seed)
    
    files_by_original_class = {}
    for f in hdr_files:
        prefix = f.stem.split("_")[0]
        if prefix not in files_by_original_class:
            files_by_original_class[prefix] = []
        files_by_original_class[prefix].append(f)
    
    original_to_mapped = {}
    for new_class, old_classes in class_mapping.items():
        for old_class in old_classes:
            original_to_mapped[old_class] = new_class
    
    files_by_mapped_class = {}
    for old_class, files in files_by_original_class.items():
        if old_class in original_to_mapped:
            mapped_class = original_to_mapped[old_class]
            if mapped_class not in files_by_mapped_class:
                files_by_mapped_class[mapped_class] = []
            files_by_mapped_class[mapped_class].extend(files)
    
    train_files = []
    test_files = []
    
    for mapped_class, files in files_by_mapped_class.items():
        random.shuffle(files)
        n_files = len(files)
        
        if n_files == 1:
            print(f"\nüî¥ Classe {mapped_class}: 1 seul fichier - {files[0].name}")
            print(f"   ‚Üí Utilisation d'un masque spatial pour diviser en train/test")
            train_files.append(files[0])
            test_files.append(files[0])
        elif n_files == 2:
            train_files.append(files[0])
            test_files.append(files[1])
            print(f"üü° Classe {mapped_class}: {n_files} fichiers ‚Üí 1 train, 1 test")
        else:
            n_train = max(1, int(train_ratio * n_files))
            n_test = n_files - n_train
            train_files.extend(files[:n_train])
            test_files.extend(files[n_train:])
            print(f"üü¢ Classe {mapped_class}: {n_files} fichiers ‚Üí {n_train} train, {n_test} test")
    
    return train_files, test_files

class Residual(nn.Module):
    def __init__(self, fn):
        super().__init__()
        self.fn = fn
    def forward(self, x):
        return self.fn(x) + x

class PreNorm(nn.Module):
    def __init__(self, dim, fn):
        super().__init__()
        self.norm = nn.LayerNorm(dim)
        self.fn = fn
    def forward(self, x):
        return self.fn(self.norm(x))

class FeedForward(nn.Module):
    def __init__(self, dim, hidden_dim, dropout=0.):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(dim, hidden_dim),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, dim),
            nn.Dropout(dropout)
        )
    def forward(self, x):
        return self.net(x)

class Attention(nn.Module):
    def __init__(self, dim, heads, dim_head, dropout):
        super().__init__()
        inner_dim = dim_head * heads
        self.heads = heads
        self.scale = dim_head ** -0.5
        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)
        self.to_out = nn.Sequential(nn.Linear(inner_dim, dim), nn.Dropout(dropout))
    def forward(self, x):
        b, n, _ = x.shape
        h = self.heads
        qkv = self.to_qkv(x).chunk(3, dim=-1)
        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=h), qkv)
        dots = torch.einsum('bhid,bhjd->bhij', q, k) * self.scale
        attn = dots.softmax(dim=-1)
        out = torch.einsum('bhij,bhjd->bhid', attn, v)
        out = rearrange(out, 'b h n d -> b n (h d)')
        return self.to_out(out)

class Transformer(nn.Module):
    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout):
        super().__init__()
        self.layers = nn.ModuleList([
            nn.ModuleList([
                Residual(PreNorm(dim, Attention(dim, heads, dim_head, dropout))),
                Residual(PreNorm(dim, FeedForward(dim, mlp_dim, dropout)))
            ]) for _ in range(depth)
        ])
    def forward(self, x):
        for attn, ff in self.layers:
            x = attn(x)
            x = ff(x)
        return x

class ViT(nn.Module):
    def __init__(self, patch_dim, num_patches, num_classes):
        super().__init__()
        dim = 64
        self.patch_to_embedding = nn.Linear(patch_dim, dim)
        self.cls_token = nn.Parameter(torch.randn(1,1,dim))
        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches+1, dim))
        self.transformer = Transformer(dim, depth=4, heads=4, dim_head=16, mlp_dim=128, dropout=0.1)
        self.mlp_head = nn.Sequential(nn.LayerNorm(dim), nn.Linear(dim, num_classes))

    def forward(self, x):
        x = self.patch_to_embedding(x)
        b, n, _ = x.shape
        cls_tokens = repeat(self.cls_token, '1 1 d -> b 1 d', b=b)
        x = torch.cat((cls_tokens, x), dim=1)
        x += self.pos_embedding[:, :(n+1)]
        x = self.transformer(x)
        return self.mlp_head(x[:,0])

def cal_results(matrix):
    shape = np.shape(matrix)
    number = 0
    summ = 0
    AA = np.zeros([shape[0]], dtype=float)
    for i in range(shape[0]):
        number += matrix[i, i]
        AA[i] = matrix[i, i] / np.sum(matrix[i, :]) if np.sum(matrix[i, :]) != 0 else 0
        summ += np.sum(matrix[i, :]) * np.sum(matrix[:, i])
    OA = number / np.sum(matrix)
    AA_mean = np.mean(AA)
    pe = summ / (np.sum(matrix) ** 2)
    Kappa = (OA - pe) / (1 - pe)
    return OA, AA_mean, Kappa, AA

# Param√®tres
data_dir = "extrudes_eroded"
class_mapping_file = "mapping.json"  # Optionnel
patch_size = 5
stride = 5
batch_size = 64
epochs = 50
learning_rate = 5e-4

# Charger le mapping si existe
class_mapping = {}
try:
    with open(class_mapping_file, 'r') as f:
        class_mapping = json.load(f)
except:
    print("Aucun fichier de mapping trouv√©, utilisation des classes originales")

# R√©cup√©rer tous les fichiers
all_hdr_files = sorted(Path(data_dir).rglob("*.hdr"))

# Diviser les fichiers
if class_mapping:
    train_files, test_files = split_files_by_class(all_hdr_files, class_mapping, train_ratio=0.7)
else:
    # Split simple sans mapping
    random.seed(42)
    random.shuffle(all_hdr_files)
    n_train = int(0.7 * len(all_hdr_files))
    train_files = all_hdr_files[:n_train]
    test_files = all_hdr_files[n_train:]

print(f"\nFichiers train: {len(train_files)}")
print(f"Fichiers test: {len(test_files)}")

# Cr√©er les datasets
train_dataset = SpectralPatchDataset(
    root_dir=data_dir,
    patch_size=patch_size,
    stride=stride,
    class_mapping_file=class_mapping_file if class_mapping else None,
    file_list=[f.name for f in train_files],
    mode='train'
)

test_dataset = SpectralPatchDataset(
    root_dir=data_dir,
    patch_size=patch_size,
    stride=stride,
    class_mapping_file=class_mapping_file if class_mapping else None,
    file_list=[f.name for f in test_files],
    mode='test'
)

print(f"\nPatches train: {len(train_dataset)}")
print(f"Patches test: {len(test_dataset)}")

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

sample_x, _ = train_dataset[0]
patch_dim = sample_x.shape[0]
num_patches = 1  # Pour ViT, chaque patch est un token

print(f"\nDimensions:")
print(f"Patch dim: {patch_dim}")
print(f"Num patches: {num_patches}")
print(f"Nombre de classes: {train_dataset.num_classes}")

model = ViT(
    patch_dim=patch_dim,
    num_patches=num_patches,
    num_classes=train_dataset.num_classes
).to(device)

print(f"\nMod√®le cr√©√© avec {sum(p.numel() for p in model.parameters())} param√®tres")

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

print("\nD√©but de l'entra√Ænement...")
for epoch in range(epochs):
    model.train()
    total_loss = 0
    correct = 0
    total = 0
    
    for x, y in train_loader:
        x, y = x.to(device), y.to(device)
        optimizer.zero_grad()
        out = model(x)
        loss = criterion(out, y)
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        _, predicted = torch.max(out, 1)
        total += y.size(0)
        correct += (predicted == y).sum().item()
    
    train_acc = 100 * correct / total
    print(f"Epoch {epoch+1:03d} | Loss: {total_loss/len(train_loader):.4f} | Train Acc: {train_acc:.2f}%")
    
    # Test tous les 5 epochs
    if (epoch + 1) % 5 == 0 or epoch == epochs - 1:
        model.eval()
        all_preds = []
        all_labels = []
        
        with torch.no_grad():
            for x, y in test_loader:
                x = x.to(device)
                out = model(x)
                _, pred = torch.max(out, 1)
                all_preds.extend(pred.cpu().numpy())
                all_labels.extend(y.numpy())
        
        if len(all_preds) > 0:
            matrix = confusion_matrix(all_labels, all_preds)
            OA, AA_mean, Kappa, AA = cal_results(matrix)
            print(f"Test - OA: {OA:.4f} | AA: {AA_mean:.4f} | Kappa: {Kappa:.4f}")

print("\n" + "="*50)
print("R√âSULTATS FINAUX")
print("="*50)
model.eval()
all_preds = []
all_labels = []

with torch.no_grad():
    for x, y in test_loader:
        x = x.to(device)
        out = model(x)
        _, pred = torch.max(out, 1)
        all_preds.extend(pred.cpu().numpy())
        all_labels.extend(y.numpy())

matrix = confusion_matrix(all_labels, all_preds)
OA, AA_mean, Kappa, AA = cal_results(matrix)

print(f"Overall Accuracy (OA): {OA:.4f}")
print(f"Average Accuracy (AA): {AA_mean:.4f}")
print(f"Kappa Coefficient: {Kappa:.4f}")
print("\nAccuracy par classe:")
for i, acc in enumerate(AA):
    class_name = train_dataset.class_names[i] if i < len(train_dataset.class_names) else f"Classe {i}"
    print(f"  {class_name}: {acc:.4f}")
print("="*50)