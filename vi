import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import spectral.io.envi as envi
from pathlib import Path
import numpy as np
from einops import rearrange, repeat
from sklearn.metrics import confusion_matrix
import torch.nn.functional as F
import json
import random

device = "cuda" if torch.cuda.is_available() else "cpu"

class SpectralPatchDataset(Dataset):
    def __init__(self, root_dir, patch_size=5, stride=5, class_mapping_file=None, 
                 file_list=None, mode='train'):
        self.root_dir = Path(root_dir)
        self.patch_size = patch_size
        self.stride = stride
        self.mode = mode
        self.samples = []
        self.labels = []
        self.class_map = {}
        self.class_names = []
        self.file_info = {}
        self.single_file_masks = {}
        
        self.class_mapping = {}
        if class_mapping_file is not None:
            with open(class_mapping_file, 'r') as f:
                self.class_mapping = json.load(f)
            print(f"Mapping des classes chargé: {self.class_mapping}")
        
        if file_list is not None:
            hdr_files = [f for f in sorted(self.root_dir.rglob("*.hdr")) if f.name in file_list]
        else:
            hdr_files = sorted(self.root_dir.rglob("*.hdr"))
        
        original_class_names = set()
        for hdr_file in hdr_files:
            name = hdr_file.stem
            prefix = name.split("_")[0]
            original_class_names.add(prefix)
        
        original_class_names = sorted(list(original_class_names))
        
        self.original_to_mapped = {}
        self.mapped_class_names = []
        
        if self.class_mapping:
            for old_class in original_class_names:
                found = False
                for new_class, old_classes in self.class_mapping.items():
                    if old_class in old_classes:
                        self.original_to_mapped[old_class] = new_class
                        if new_class not in self.mapped_class_names:
                            self.mapped_class_names.append(new_class)
                        found = True
                        break
                if not found:
                    print(f"Attention: La classe {old_class} n'est pas mappée, elle sera ignorée")
        else:
            for old_class in original_class_names:
                self.original_to_mapped[old_class] = old_class
            self.mapped_class_names = original_class_names.copy()
        
        self.mapped_class_names = sorted(self.mapped_class_names)
        for idx, name in enumerate(self.mapped_class_names):
            self.class_map[name] = idx
            self.class_names.append(name)
        
        self.num_classes = len(self.class_names)
        
        class_file_count = {}
        for hdr_file in hdr_files:
            name = hdr_file.stem
            prefix = name.split("_")[0]
            if prefix in self.original_to_mapped:
                mapped_class = self.original_to_mapped[prefix]
                class_file_count[mapped_class] = class_file_count.get(mapped_class, 0) + 1
        
        self.single_file_classes = {cls for cls, count in class_file_count.items() if count == 1}
        if self.single_file_classes:
            print(f"Classes avec un seul fichier: {self.single_file_classes}")
        
        all_samples = []
        all_labels = []
        
        for hdr_file in hdr_files:
            name = hdr_file.stem
            prefix = name.split("_")[0]
            
            if prefix not in self.original_to_mapped:
                continue
            
            mapped_class = self.original_to_mapped[prefix]
            class_id = self.class_map[mapped_class]
            
            img = envi.open(str(hdr_file))
            cube = np.array(img.load(), dtype=np.float32)
            B, H, W = cube.shape
            
            cube_tensor = torch.from_numpy(cube).float().unsqueeze(0)
            
            if mapped_class in self.single_file_classes:
                mask = self._create_checkerboard_mask(H, W)
                self.single_file_masks[hdr_file.name] = mask
                patches = self._extract_patches_with_mask(cube_tensor, self.patch_size, self.stride, mask)
            else:
                patches = self._extract_patches_with_unfold(cube_tensor, self.patch_size, self.stride)
            
            self.file_info[hdr_file.name] = {
                'class': mapped_class,
                'class_id': class_id,
                'num_patches': len(patches)
            }
            
            for patch in patches:
                all_samples.append(patch)
                all_labels.append(class_id)
        
        self.samples = all_samples
        self.labels = all_labels
        
        print(f"Mode {mode}: {len(self.samples)} patches chargés")
    
    def _create_checkerboard_mask(self, height, width, cell_size=4):
        mask = np.zeros((height, width), dtype=bool)
        for i in range(height):
            for j in range(width):
                if ((i // cell_size) + (j // cell_size)) % 2 == 0:
                    mask[i, j] = True
                else:
                    mask[i, j] = False
        return mask
    
    def _extract_patches_with_unfold(self, cube_tensor, patch_size, stride):
        patches = F.unfold(cube_tensor, kernel_size=(patch_size, patch_size), dilation=1, stride=stride, padding=1)
        B = cube_tensor.shape[1]
        L = patches.shape[-1]
        patches = patches.squeeze(0)
        patches = patches.reshape(B, patch_size * patch_size, L)
        patches = patches.permute(2, 0, 1)
        patches = patches.reshape(L, B, patch_size, patch_size)
        patch_list = []
        for i in range(L):
            patch = patches[i].numpy()
            patch_list.append(patch)
        return patch_list
    
    def _extract_patches_with_mask(self, cube_tensor, patch_size, stride, mask):
        B, H, W = cube_tensor.shape[1], cube_tensor.shape[2], cube_tensor.shape[3]
        
        patches = F.unfold(cube_tensor, kernel_size=(patch_size, patch_size), dilation=1, stride=stride, padding=1)
        L = patches.shape[-1]
        
        patches = patches.squeeze(0)
        patches = patches.reshape(B, patch_size * patch_size, L)
        patches = patches.permute(2, 0, 1)
        patches = patches.reshape(L, B, patch_size, patch_size)
        
        padding = patch_size // 2
        patch_list = []
        idx = 0
        
        for i in range(0, H - patch_size + 1, stride):
            for j in range(0, W - patch_size + 1, stride):
                if idx >= L:
                    break
                center_i = i + patch_size//2 - padding
                center_j = j + patch_size//2 - padding
                
                if 0 <= center_i < mask.shape[0] and 0 <= center_j < mask.shape[1]:
                    if self.mode == 'train' and mask[center_i, center_j]:
                        patch_list.append(patches[idx].numpy())
                    elif self.mode == 'test' and not mask[center_i, center_j]:
                        patch_list.append(patches[idx].numpy())
                idx += 1
        
        return patch_list
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        x = self.samples[idx]
        y = self.labels[idx]
        x = x.reshape(-1)
        return torch.FloatTensor(x), torch.LongTensor([y])[0]

def split_files_by_class(hdr_files, class_mapping, train_ratio=0.7, random_seed=42):
    random.seed(random_seed)
    
    files_by_original_class = {}
    for f in hdr_files:
        prefix = f.stem.split("_")[0]
        if prefix not in files_by_original_class:
            files_by_original_class[prefix] = []
        files_by_original_class[prefix].append(f)
    
    original_to_mapped = {}
    for new_class, old_classes in class_mapping.items():
        for old_class in old_classes:
            original_to_mapped[old_class] = new_class
    
    files_by_mapped_class = {}
    for old_class, files in files_by_original_class.items():
        if old_class in original_to_mapped:
            mapped_class = original_to_mapped[old_class]
            if mapped_class not in files_by_mapped_class:
                files_by_mapped_class[mapped_class] = []
            files_by_mapped_class[mapped_class].extend(files)
    
    train_files = []
    test_files = []
    
    for mapped_class, files in files_by_mapped_class.items():
        random.shuffle(files)
        n_files = len(files)
        
        if n_files == 1:
            print(f"\nClasse {mapped_class}: 1 seul fichier - {files[0].name}")
            print(f"   → Utilisation d'un masque spatial pour diviser en train/test")
            train_files.append(files[0])
            test_files.append(files[0])
        elif n_files == 2:
            train_files.append(files[0])
            test_files.append(files[1])
            print(f"Classe {mapped_class}: {n_files} fichiers → 1 train, 1 test")
        else:
            n_train = max(1, int(train_ratio * n_files))
            n_test = n_files - n_train
            train_files.extend(files[:n_train])
            test_files.extend(files[n_train:])
            print(f"Classe {mapped_class}: {n_files} fichiers → {n_train} train, {n_test} test")
    
    return train_files, test_files

class Residual(nn.Module):
    def __init__(self, fn):
        super().__init__()
        self.fn = fn
    def forward(self, x):
        return self.fn(x) + x

class PreNorm(nn.Module):
    def __init__(self, dim, fn):
        super().__init__()
        self.norm = nn.LayerNorm(dim)
        self.fn = fn
    def forward(self, x):
        return self.fn(self.norm(x))

class FeedForward(nn.Module):
    def __init__(self, dim, hidden_dim, dropout=0.):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(dim, hidden_dim),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim, dim),
            nn.Dropout(dropout)
        )
    def forward(self, x):
        return self.net(x)

class Attention(nn.Module):
    def __init__(self, dim, heads, dim_head, dropout):
        super().__init__()
        inner_dim = dim_head * heads
        self.heads = heads
        self.scale = dim_head ** -0.5
        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias=False)
        self.to_out = nn.Sequential(nn.Linear(inner_dim, dim), nn.Dropout(dropout))
    def forward(self, x):
        b, n, _ = x.shape
        h = self.heads
        qkv = self.to_qkv(x).chunk(3, dim=-1)
        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h=h), qkv)
        dots = torch.einsum('bhid,bhjd->bhij', q, k) * self.scale
        attn = dots.softmax(dim=-1)
        out = torch.einsum('bhij,bhjd->bhid', attn, v)
        out = rearrange(out, 'b h n d -> b n (h d)')
        return self.to_out(out)

class Transformer(nn.Module):
    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout):
        super().__init__()
        self.layers = nn.ModuleList([
            nn.ModuleList([
                Residual(PreNorm(dim, Attention(dim, heads, dim_head, dropout))),
                Residual(PreNorm(dim, FeedForward(dim, mlp_dim, dropout)))
            ]) for _ in range(depth)
        ])
    def forward(self, x):
        for attn, ff in self.layers:
            x = attn(x)
            x = ff(x)
        return x

class ViT(nn.Module):
    def __init__(self, patch_dim, num_patches, num_classes):
        super().__init__()
        dim = 64
        self.patch_to_embedding = nn.Linear(patch_dim, dim)
        self.cls_token = nn.Parameter(torch.randn(1,1,dim))
        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches+1, dim))
        self.transformer = Transformer(dim, depth=4, heads=4, dim_head=16, mlp_dim=128, dropout=0.1)
        self.mlp_head = nn.Sequential(nn.LayerNorm(dim), nn.Linear(dim, num_classes))

    def forward(self, x):
        x = self.patch_to_embedding(x)
        x = x.unsqueeze(1)
        b, n, _ = x.shape
        cls_tokens = repeat(self.cls_token, '1 1 d -> b 1 d', b=b)
        x = torch.cat((cls_tokens, x), dim=1)
        x += self.pos_embedding[:, :(n+1)]
        x = self.transformer(x)
        return self.mlp_head(x[:,0])

def cal_results(matrix):
    shape = np.shape(matrix)
    number = 0
    summ = 0
    AA = np.zeros([shape[0]], dtype=float)
    for i in range(shape[0]):
        number += matrix[i, i]
        AA[i] = matrix[i, i] / np.sum(matrix[i, :]) if np.sum(matrix[i, :]) != 0 else 0
        summ += np.sum(matrix[i, :]) * np.sum(matrix[:, i])
    OA = number / np.sum(matrix)
    AA_mean = np.mean(AA)
    pe = summ / (np.sum(matrix) ** 2)
    Kappa = (OA - pe) / (1 - pe)
    return OA, AA_mean, Kappa, AA

data_dir = "extrudes_eroded"
class_mapping_file = "mapping.json"
patch_size = 5
stride = 5
batch_size = 64
epochs = 50
learning_rate = 5e-4
train_ratio = 0.7

all_hdr_files = sorted(Path(data_dir).rglob("*.hdr"))

try:
    with open(class_mapping_file, 'r') as f:
        class_mapping = json.load(f)
    print("Mapping chargé avec succès")
    train_files, test_files = split_files_by_class(all_hdr_files, class_mapping, train_ratio)
except FileNotFoundError:
    print("Aucun fichier de mapping trouvé, split aléatoire simple")
    random.seed(42)
    random.shuffle(all_hdr_files)
    n_train = int(train_ratio * len(all_hdr_files))
    train_files = all_hdr_files[:n_train]
    test_files = all_hdr_files[n_train:]
    class_mapping = None

print(f"\nFichiers train: {len(train_files)}")
print(f"Fichiers test: {len(test_files)}")

train_dataset = SpectralPatchDataset(
    root_dir=data_dir,
    patch_size=patch_size,
    stride=stride,
    class_mapping_file=class_mapping_file if class_mapping else None,
    file_list=[f.name for f in train_files],
    mode='train'
)

test_dataset = SpectralPatchDataset(
    root_dir=data_dir,
    patch_size=patch_size,
    stride=stride,
    class_mapping_file=class_mapping_file if class_mapping else None,
    file_list=[f.name for f in test_files],
    mode='test'
)

print(f"\nPatches train: {len(train_dataset)}")
print(f"Patches test: {len(test_dataset)}")

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

sample_x, _ = train_dataset[0]
print(f"\nDimension d'un patch: {sample_x.shape}")

model = ViT(
    patch_dim=sample_x.shape[0],
    num_patches=1,
    num_classes=train_dataset.num_classes
).to(device)

print(f"Modèle créé avec {sum(p.numel() for p in model.parameters())} paramètres")
print(f"Nombre de classes: {train_dataset.num_classes}")

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

print("\nDébut de l'entraînement...")
for epoch in range(epochs):
    model.train()
    total_loss = 0
    correct = 0
    total = 0
    
    for x, y in train_loader:
        x, y = x.to(device), y.to(device)
        optimizer.zero_grad()
        out = model(x)
        loss = criterion(out, y)
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        _, predicted = torch.max(out, 1)
        total += y.size(0)
        correct += (predicted == y).sum().item()
    
    train_acc = 100 * correct / total
    print(f"Epoch {epoch+1:03d} | Loss: {total_loss/len(train_loader):.4f} | Train Acc: {train_acc:.2f}%")
    
    if (epoch + 1) % 5 == 0 or epoch == epochs - 1:
        model.eval()
        all_preds = []
        all_labels = []
        
        with torch.no_grad():
            for x, y in test_loader:
                x = x.to(device)
                out = model(x)
                _, pred = torch.max(out, 1)
                all_preds.extend(pred.cpu().numpy())
                all_labels.extend(y.numpy())
        
        if len(all_preds) > 0:
            matrix = confusion_matrix(all_labels, all_preds)
            OA, AA_mean, Kappa, AA = cal_results(matrix)
            print(f"Test - OA: {OA:.4f} | AA: {AA_mean:.4f} | Kappa: {Kappa:.4f}")

print("\n" + "="*50)
print("RÉSULTATS FINAUX")
print("="*50)
model.eval()
all_preds = []
all_labels = []

with torch.no_grad():
    for x, y in test_loader:
        x = x.to(device)
        out = model(x)
        _, pred = torch.max(out, 1)
        all_preds.extend(pred.cpu().numpy())
        all_labels.extend(y.numpy())

matrix = confusion_matrix(all_labels, all_preds)
OA, AA_mean, Kappa, AA = cal_results(matrix)

print(f"Overall Accuracy (OA): {OA:.4f}")
print(f"Average Accuracy (AA): {AA_mean:.4f}")
print(f"Kappa Coefficient: {Kappa:.4f}")
print("\nAccuracy par classe:")
for i, acc in enumerate(AA):
    class_name = train_dataset.class_names[i] if i < len(train_dataset.class_names) else f"Classe {i}"
    print(f"  {class_name}: {acc:.4f}")
print("="*50)